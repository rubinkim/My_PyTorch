{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ce296b-f534-45a7-a150-de37be2c5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules needed\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision                                  # computer vision package\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b168c986-4cb5-4b78-87dc-262b0e488cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([256, 256]),                  # Adjust image size to 256*256\n",
    "    transforms.RandomResizedCrop(224),              # Crop a random portion of image and resize it to 224\n",
    "    transforms.RandomHorizontalFlip(),              # Horizontally flip the given image randomly with a given probability, Default prop is 0.5\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f28eef-ece8-424b-b7ff-59265b33bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../My_PyTorch_Data/gilbut/chap05/data/catanddog/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5bc790-00ef-4493-bd00-892cc7291664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬에 저장된 이미지 데이터를 불러올 때 사용하는 PyTorch 라이브러리이다.\n",
    "# 분류하려는 label의 class개수에 따라 folder를 생성하고 그 안에 해당 label에 맞는 이미지를 저장한다.\n",
    "# ImageFolder를 사용하려면 기본적인 디렉토리 골격을 지켜줘야 한다.\n",
    "# 주목할 점은 제일 하위 디렉토리가 클래스명으로 이루어져 있다는 거다.\n",
    "# 일반적으로 train, test용으로 각각 ImageFolder 객체를 생성한다.\n",
    "# - train_imgfolder = ImageFolder(root = 'data/train', transform=transform)\n",
    "# - test_imgfolder = ImageFolder(root = 'data/test', transform=transform)\n",
    "# root에 입력된 path정보를 통해 해당경로 하위에 class명 디렉토리가 위치한다는 걸 ImageFolder가 알 수 있다.\n",
    "# DataLoader에 train_imgfolder과 test_imgfolder를 각각 넣어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871384f0-1ca6-45da-a814-55ebe9cbd469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog']\n",
      "{'Cat': 0, 'Dog': 1}\n"
     ]
    }
   ],
   "source": [
    "# A generic data loader where the images are arranged in this way by default\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transform)\n",
    "print(train_dataset.classes)\n",
    "print(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde65087-9c9d-49d4-9838-7baf0cd964a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002C82ED53B80>\n",
      "samples shape : torch.Size([32, 3, 224, 224]),   labels shape : torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, num_workers=8, shuffle=True)\n",
    "print(train_loader)\n",
    "\n",
    "samples, labels = iter(train_loader).next()\n",
    "print(f\"samples shape : {samples.shape},   labels shape : {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3012e27d-93a2-469d-9115-c041abca5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aafe2a38-bc8b-4690-815e-b497e0a87999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 1 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 2 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 3 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 4 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 5 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 6 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 7 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 8 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      " 9 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      "10 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      "11 : inputs shape : torch.Size([32, 3, 224, 224]),  labels shape : torch.Size([32])\n",
      "12 : inputs shape : torch.Size([1, 3, 224, 224]),  labels shape : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(f\"{i:2d} : inputs shape : {inputs.shape},  labels shape : {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76be03ef-ab7d-49b3-aa54-c75a44f57707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    }
   ],
   "source": [
    "print(32 * 12 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "860b1953-f872-4a29-9d72-895cce375579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {0 : 'cat', 1 : 'dog'}\n",
    "\n",
    "classes[labels[1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5d288-66a1-46be-aa39-34f95deb10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0 : 'cat', 1 : 'dog'}\n",
    "\n",
    "fig = plt.figure(figsize=(16, 24))\n",
    "for i in range(24):\n",
    "    a = fig.add_subplot(4, 6, i+1)\n",
    "    a.set_title(classes[labels[i].item()])          # classes[labels[1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
